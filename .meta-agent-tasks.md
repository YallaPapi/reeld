# Meta-Agent Implementation Tasks

## Instructions for Claude Code

This file contains implementation tasks identified by meta-agent analysis.

### IMPORTANT: Use Taskmaster for Implementation

**You MUST use Taskmaster to implement these tasks.** Do NOT manage tasks manually.

To import these tasks into Taskmaster:
```bash
# Parse this file as a PRD to add tasks to Taskmaster
task-master parse-prd .meta-agent-tasks.md --append

# Then work through tasks using Taskmaster commands:
task-master list                    # See all tasks
task-master next                    # Get next task to work on
task-master set-status --id=<id> --status=in-progress
task-master set-status --id=<id> --status=done
```

### Task Workflow:
1. Import tasks into Taskmaster using `parse-prd --append`
2. Use `task-master next` to get the highest priority task
3. Mark task as `in-progress` before starting
4. Implement the task following the description below
5. Mark task as `done` when complete
6. Commit changes after completing related tasks

---

## Task Summary

- **Critical:** 3 task(s)
- **High:** 2 task(s)
- **Medium:** 2 task(s)
- **Low:** 1 task(s)
- **Total:** 8 task(s)

---

## Tasks

### 1. ðŸ”´ Create centralized analytics tracking module

- [ ] **Status:** Not started
- **Priority:** Critical
- **File:** `analytics.py`

**Description:**

Build analytics.py with thread-safe metrics collector for: videos_processed, captions_generated, claude_api_calls, processing_times, errors. Support batch flushes for parallel workers. Use SQLite for storage with schema: runs(timestamp), metrics(run_id, script_name, metric_type, value, timestamp).

### 2. ðŸ”´ Build FastAPI backend for dashboard

- [ ] **Status:** Not started
- **Priority:** Critical
- **File:** `dashboard.py`

**Description:**

Create dashboard.py FastAPI server with endpoints: /api/metrics/today, /api/metrics/{days}, /api/pipeline-status, /api/api-usage. Query SQLite analytics db. Add /api/runs endpoint for pipeline execution history. Include CORS for frontend.

### 3. ðŸ”´ Create React/Vue frontend dashboard

- [ ] **Status:** Not started
- **Priority:** Critical
- **File:** `frontend/`

**Description:**

Build frontend/ with dashboard showing: 1) KPIs (videos processed, captions generated, API calls today), 2) Pipeline status timeline, 3) 7/30-day trend charts, 4) Per-script breakdown tables, 5) API cost estimator. Use Chart.js/Recharts.

### 4. ðŸŸ  Instrument parallel_download.py with analytics

- [ ] **Status:** Not started
- **Priority:** High
- **File:** `parallel_download.py`

**Description:**

Add analytics tracking to parallel_download.py: total_videos_attempted, videos_skipped_exists, videos_successful, total_download_time, avg_download_speed. Track per username folder stats. Flush metrics at completion using new analytics module.

### 5. ðŸŸ  Instrument spoof_videos.py and generate_csv_from_mapping.py

- [ ] **Status:** Not started
- **Priority:** High
- **File:** `spoof_videos.py, generate_csv_from_mapping.py`

**Description:**

Add tracking to spoof_videos.py: videos_spoofed, spoofing_time_per_video, gpu_utilization_estimate, crop/scale/trim params stats. For generate_csv_from_mapping.py: captions_rewritten, claude_api_calls, api_errors, csv_rows_generated, chunk_stats.

### 6. ðŸŸ¡ Add optional analytics to all scripts

- [ ] **Status:** Not started
- **Priority:** Medium
- **File:** `parallel_download.py, spoof_videos.py, embed_audio_id.py, extract_audio_id.py, generate_csv_from_mapping.py`

**Description:**

Add ENABLE_ANALYTICS env var (default=true) to all processing scripts. Minimal 2-line integration using analytics.track() calls. Create auto-instrumentation decorator for worker functions.

### 7. ðŸŸ¡ Pipeline status tracking and alerts

- [ ] **Status:** Not started
- **Priority:** Medium
- **File:** `dashboard.py, analytics.py`

**Description:**

Add pipeline_state.json with current_step, progress_pct, start_time, pid. Dashboard polls this file. Add simple email/Slack alerts for failures via SMTP or webhook when metrics show errors > threshold.

### 8. ðŸŸ¢ Docker setup for dashboard

- [ ] **Status:** Not started
- **Priority:** Low
- **File:** `docker-compose.yml, Dockerfile`

**Description:**

Create docker-compose.yml with FastAPI backend + frontend + SQLite volume. Expose port 8080. Include nginx reverse proxy. Add to project root README.
